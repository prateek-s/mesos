

<2016-08-26 Fri>

- AWS integration 
  ::PARTIAL::
- Allocator. Packing and framework lifecycle.
- Idle server identification and hold-time
- JSON parsing of portfolios 
- Inverse offer construction and parsing 
  ::STARTED::
- General C++ Job-manager 
- Spark cloudinfo, checkpointing policy 
- 


<2016-08-29 Mon>
- Porfolio parsing 

- Bring EC2 code into CRM 

- 

<2016-08-21 Sun>

* Slave
** Read the role/default_owner in slave.cpp when registering slave 
slave.cpp

::DONE:: <2016-08-22 Mon>

** Read the meta-data for instance-type and avail-zone via curl/http whatevs
slave.cpp registering code in info again!

::DONE:: <2016-08-22 Mon>

** relay_warning
::DONE::

* CRM
** Read the attributes from the slaves
- type
- owner_fmwk
- avail zone          

::DONE:: 

** Add EC2 server size information for all the slaves 
::DONE::

** Parse the portfolio allocations
   Python code should emit clean portflio allocations! One alpha per file? 
   alpha, <instance-id+az: wt>, 

::STARTED:: USE JSON!

** Add registered slaves to some list?



** Call alloc_slave_to_fmwk
::DONE::

** Policy switches 
Better private/packing code-paths to ensure that private mode is independent of other policy options and works end-to-end 



** Resource parsing 
CPU/memory into one, and then do some vector arithmetic to see if we can pack? 
Is using mesos::resources even the right way? Use our own resource vector? 



** Handle framework termination
- Note somewhere?
- Deallocate its resources from slaves
- Put slaves on some idle list? This is why having actual roles for slaves is not such a good idea. We want the owner_framework to mainly help in identification of the slave and which framework it should be actually allocated to. 

::TODO::

** Repair

::TODO:: 

Doing this might be non-trivial, because we need to know how many resources the framework has lost, and then try acquiring those resources (from some different market) again. 

* Allocator

** alloc_slave_to_fmwk implementation
::TODO::

** Tell allocator about the cloudmachine info
::DONE::

<2016-08-22 Mon>

** Parse resources here? 

** Task end recovery?
When a task ends, the resources are freed.

*** How does the master get the message 

*** How does the allocator respond? 
    Presumably in =recoverResources=, frameworksorters[role]->unallocated(resources)

*** How to modify recovery with the partitioned allocator? 
    Only reclaim on framework end? 

* Applications

** Standalone C++ application job-manager 
CloudInfo
TerminationWarning


<2016-08-21 Sun>


** Resource requests by frameworks can come with an optional "resiliency" parameter. Pass these parameters to the CloudResourceManager (in crm.cpp) 


** Slave properties must also have region, server-type, avail-zone, AMI, pricing, and availability information. 

slave/flags.cpp attributes. Can be of the form rack:foo , region:X, etc. Need compulsory attributes though! 

** CloudRM acts as the allocator. New frameworks and resource requests act as "allocs", and removed frameworks call upon "deletes".

** Get the resource utilization and free resource availability for each slave. 

slave/slave.hpp   // Returns the resource usage information for all executors.
  virtual process::Future<ResourceUsage> usage();


** CRM, upon resource_request. Scan all slaves, and see if the request can be granted. Else, request more server resources. 

** Warning propagation 

Slaves send the ec2 termination warning to the master via the status update mechanism 
slave/status_update_manager.cpp 

** Slave management
master.hpp struct slaves 

~/code/mesos/build/include/mesos/mesos.pb.h for the machineinfo class, which may be better than slaves, since multiple slaves can belong to a single machine etc. 

** Machine maintenance mode 

~/code/mesos/include/mesos/v1/maintenance/maintenance.proto

Apparently we can specify unavailability of machine groups!

Unavailability can also be captured in terms of inverse offers. 


