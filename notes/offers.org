Resource offers can have arbitrary attributes as key-value pairs which it passes  along to the frameworks.

Mesos agents (nodes) can have attributes like --attributes='rack:abc;zone:west;os:centos5;level:10;keys:[1000-1500]'

*Question*: Stand-alone cluster (one per application), or multiple applications per cluster? With multiple applications, we may get better utilization, but at a higher complexity. 

*Question*: How to handle elasticity in demands and due to job arrivals? When to request new nodes from EC2? Should we keep some idle resource capacity at all times to speed up the allocation? This seems like a classic cost vs. latency tradeoff. One policy could be to always request new resources on-demand only. Another one could be something like the "slab allocator", where we keep some ec2 servers in a "cache" and then fulfill the allocation when required. 


*Question*: How to implement packing within mesos to reduce the costs?


* Allocation loop

Requiring dynamic price-driven allocation is going to be hard because of these factors:
1. Huge number of markets (~500 per region)

2. High latency and low reliability to get the latest pricing data. This means we might have to keep prices cached, or be ready to use older pricing, or be lazy with the price getting mechanism. All of this will require careful synchronization. 

3. If we support budgets (say max total hourly price over all instances), then we might have to check every time we decide to allocate a new node : while(total_prices < budget){..} . This check, if done with actual real time prices, might again take a long time to compute for all the markets (few hundred http calls). An alternative could be a price mirroring proxy which handles all these complexities for the mesos clusters. Presumably, this proxy can do the async gets, provide stale results if necessary, and also do efficient batched queries (return the prices of [mkt1, mkt2, ...]). 


Handling dynamism would be hard. How often to update the correlation matrix? 


*Question*: How do applications specify their resource requirements? In spark, number of cores and mem per core can be specified, as well as the coarse-grained/fine-grained option. Along with that, we can also specify the node attributes (such as "us-east-1"), which can be used to specify single/multiple failure domains.


*Question*: Combining DRF with transiency aware allocation.

Simplest case: single application. Infer/get application requirements-> create a cluster, and done. Some dynamism still required. Handle/pass revocations etc. 

Multiple applications submitted at the same time : need to statically partition. Dynamic allocation not required. 

Jobs can arrive at any time. Get free resources first, then 

Spot instance startup times can be much higher---so keeping a cache around might be useful. 





* Simulation



* Architecture 

Mesos -> EC2 layer 


EC2 layer gets the servers, gets the prices, etc. What does mesos really want from the ec2 layer? What should the API be? 
get_new_server()
get_diff_market()

State that mesos (core) has:
Servers/Nodes
Market mapping
Correlation matrix - Required for creating the multi-market resource offers. 
?Price info?
?Avail info?




