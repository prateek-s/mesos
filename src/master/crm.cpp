#include <iostream>
//#include <sstream>

#include <process/defer.hpp>
#include <process/dispatch.hpp>
#include <process/future.hpp>
#include <process/http.hpp>

//#include <mesos/state/log.hpp>

// #include <stout/check.hpp>
// #include <stout/duration.hpp>
// #include <stout/exit.hpp>
// #include <stout/flags.hpp>
// #include <stout/nothing.hpp>
// #include <stout/option.hpp>
// #include <stout/os.hpp>
// #include <stout/path.hpp>
// #include <stout/stringify.hpp>
// #include <stout/strings.hpp>
// #include <stout/try.hpp>


//using mesos::log::Log;

#include "master/crm.hpp"

//using std::string;
using namespace std ;

CloudRM::CloudRM()
{
  LOG(INFO) << "~~~ FROM CLOUD RM" ;
  std::cout << "  CLOUD RM \n" ;
}

/********************************************************************************/

/* The frameworkinfo structure has a lot of metadata about the framework, which can be used by some policies eventually to directly allocate resources to it even if they dont ask for it explicitly. This can be some basic rule engine etc. 
Return a vector of server orders here? 
 */
vector<ServerOrder> CloudRM::pDefaultFrameworkResources(const mesos::FrameworkInfo& frameworkinfo)
{
  //add_to_pending_orders(frameworkinfo);
  ServerOrder* order = new ServerOrder() ;
  //really should be a vector or a collection of orders.
  std::vector<ServerOrder> all_orders ;
  all_orders.push_back(*order) ;
  return all_orders ;
}


int CloudRM::init(mesos::internal::master::Master* master)
{
  this->master = master ;
  LOG(INFO) << "~~~~~~~ INITIALIZED by master" ;
  return 1; 
}

/********************************************************************************/

 /* A new framework has been registered with us. Most frameworks will subsequently ask for resources once they have been registered with the mesos master. We can put the framework on some sort of a pending list? 
 */
int CloudRM::new_framework(const mesos::FrameworkInfo& frameworkinfo)
{
  LOG(INFO) << "~~~~~~~ NEW FRAMEWORK" ;
  std::string fid ;
  
  if(frameworkinfo.has_id()) {
    fid = frameworkinfo.id().value() ;
  }
  if(new_framework_starter_nodes==0){
    return 0;
  }
    
  /* Create the server order vector for the framework according to some rule engine*/
  std::vector<ServerOrder> order = pDefaultFrameworkResources(frameworkinfo) ;
  
  //add_to_pending_orders 
  if(!order.empty()) {
    LOG(INFO) << "Something in order " ;
    add_to_pending_orders(order) ;
    /* Now ask the cloud layer to fulfill this order for us */
//     process:dispatch(AwsAgent, GetServers, order) 
  }
  return 1; 
}

/********************************************************************************/

void CloudRM::add_to_pending_orders(std::vector<ServerOrder> orders)
{
  
  
}

/********************************************************************************/

/* Return portfolio wts for a given alpha. Read in csv file of some sort generated by the python cvxopt solver. 
*/
hashmap<CloudMachine, int> CloudRM::get_portfolio_wts(double alpha)
{
  hashmap<CloudMachine, int> out ;
  return out ;
}

/********************************************************************************/

/* Determine number of servers to satisfy w*cpu and w*memory from a given market. Depends only on the type. Servers might end up being too small for an application, in which case we cant do anything now! 
*/
ServerOrder CloudRM::get_min_servers(double wt, const CloudMachine& cm, ResourceVector& req)
{
  ServerOrder out ;
  std::string type = cm.type ;
  LOG(INFO) << "Finding servers of type " << type ;
  
  //1. Multiply the resource vector by weight to get
  double req_cpu = req.get_cpu() * wt ; 
  double req_mem = req.get_mem() * wt ;
  
  //2. Get CPU and mem capacity of the given server type
  int cap_cpu = EC2_machines.get_cpu(type) ;
  int cap_mem = EC2_machines.get_mem(type) ;
  
  //3. Compute min numbers here?
  double min_for_cpu = req_cpu/cap_cpu ;
  double min_for_mem = req_mem/cap_mem ;
  
  int order_count = ceil(std::max(min_for_mem, min_for_cpu)) ;

  out.num = order_count ;
  out.machine = cm ;
  return out ;
}

/********************************************************************************/

/* Translates portfolio weights to actual servers. The wts indicate what fraction of the application should be running on servers in that market. If wt=1, then simply determine how many servers we need from this market to satisfy the cpu AND memory resources. In fact lets do this. 
 */
std::vector<ServerOrder> CloudRM::compute_server_order(hashmap<CloudMachine, int> & portfolio_wts, ResourceVector& req, std::string packing_policy)
{
  std::vector<ServerOrder> out ; 
  //1. For each market, determine min servers to satisfy w*cpu and w*memory
  foreachkey(const CloudMachine& cm, portfolio_wts) {
    double wt = portfolio_wts[cm] ;
    ServerOrder in_market = get_min_servers(wt, cm, req) ;
    
    if(in_market.num==0) {
      //Server type too small maybe?
      LOG(INFO) << "Cannot meet server order requirement, too small" ;
    }
    else {
      out.push_back(in_market) ;
    }
  } //end foreachkey
  return out ;
}

/********************************************************************************/

/** Get the actual servers which must be ordered. 
 */
std::vector<ServerOrder> CloudRM::get_servers(mesos::internal::master::Framework* framework, ResourceVector& req, PlacementConstraint& placement, std::string packing_policy)
{
  std::vector<ServerOrder> out ;
  if(packing_policy!="none") {
    LOG(INFO) << "Packing policy " << packing_policy << " is NOT supported " ;
    return out ;
  }

  //1. Find the portfolio-vector for the given alpha first.
  hashmap<CloudMachine, int> portfolio_wts = get_portfolio_wts(placement.alpha) ;
  //2. Translate wts into actual number of servers we need!
  out = compute_server_order(portfolio_wts, req, packing_policy) ;
  return out ;
}

/********************************************************************************/

/**
 * Resource request made by a framework. Framework->offeredResources is partitioned by slaveId, and we do packing etc based off of that. 
 */
void CloudRM::res_req(mesos::internal::master::Framework* framework, const std::vector<mesos::Request>& requests)
{
  LOG(INFO) << "~~~~~~ REQ RCVD " ;
  //1. Check if resources requested + totalUsedResources is within bounds or not?
  //2. See if we can find some free resources on any machine to fill these demands
  // find_free(framework, requests, constraints) ;
  //3. Buy more cloud servers if required.
  //4. Make this a Future/Promise thingy so that we know the execution context (the framework which actually requested these servers.
  //5. Once the new servers are up, do we need to perform the packing again?

  ResourceVector req ;
  req.extract_resource_vector(requests) ;
  PlacementConstraint placement ;
  placement.extract_placement_constraint(requests) ;

  std::vector<ServerOrder>to_buy = get_servers(framework, req, placement, packing_policy) ;
  //TODO: tag all these orders with the framework and AMI? 
  //Actually ask amazon for these servers? 
  finalize_server_order(to_buy, framework) ;

  bool ec2_buy = false ;
  std::vector<ServerOrder> servers ;
  
  if(ec2_buy) {
    //CALL EC2 libraries here.
    
  } else {
    servers = to_buy ;
  }
  framework->ServerOrders = servers  ;
  framework->numServersAssigned = servers.size() ;
  
}

/********************************************************************************/

/* Fill in the server order with the framework and the AMI information if needed?
 */
void CloudRM::finalize_server_order(std::vector<ServerOrder>& to_buy, mesos::internal::master::Framework* framework)
{
  std::string frameworkID ; //=framework->frameworkID ;
  std::string ami = "8y4982" ;
  for(auto order : to_buy) {
    order.framework = frameworkID ;
    order.ami = ami ;
  }
}

/********************************************************************************/

/**
 * How to represent constraints? It can either be just some alpha for now.
 * Other locality constraints may be supported in the future. 
 */
void find_free(mesos::internal::master::Framework* framework, std::vector<mesos::Request>& requests, std::vector<int> constraints) {
  //This is where the packing logic is implemented. 

}

/********************************************************************************/

void CloudRM::foo()
{
  LOG(INFO) << "~~~~~~~ FOO " ;

}

int CloudRM::bar()
{
  LOG(INFO) << "~~~~~~~ BAR CALLED " ;
  return 32; 
}

/********************************************************************************/
